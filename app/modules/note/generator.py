from __future__ import annotations

import re
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from difflib import SequenceMatcher
from html import escape
from typing import Callable, Dict, List, Optional, Tuple

from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage

from app.modules.note.llm_client import get_llm
from app.modules.note.style_policies import (
    StyleProfile,
    build_style_instructions,
    build_style_profile,
)
from app.schemas.common import (
    AnchorRef,
    LayoutDoc,
    LayoutElement,
    NoteDoc,
    NoteEquation,
    NoteFigure,
    NoteSection,
    OutlineNode,
    OutlineTree,
)
from app.storage.vector_store import load_or_create, save
from app.utils.identifiers import new_id
from app.utils.logger import logger
from app.utils.outline import render_outline_markdown
from app.utils.text import normalize_whitespace, take_sentences


PAGE_HEADING_PATTERN = re.compile(
    r"^(?P<leading>#{2,6})\s*"
    r"(?:ç¬¬\s*(?P<page_cn>\d+)\s*é¡µ|Page\s+(?P<page_en>\d+))"
    r"(?:\s*[:ï¼š-]\s*(?P<rest>.*))?\s*$",
    re.IGNORECASE | re.MULTILINE,
)


class NoteGenerator:
    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50, max_workers: int = 3):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.max_workers = max(1, max_workers)

    # --- è¯­ä¹‰ RAG æ•°æ®åº“æ„å»º ---
    def _build_semantic_documents(
        self, outline: OutlineTree, layout_doc: LayoutDoc
    ) -> tuple[List[Document], dict[str, str]]:
        page_text_map = self._extract_page_text(layout_doc)
        documents: List[Document] = []
        section_contexts: dict[str, str] = {}
        for section in outline.root.children:
            context_text = self._compose_block_context(section, page_text_map)
            metadata = {
                "section_id": section.section_id,
                "title": section.title,
                "page_span": self._format_page_span(section),
                "page_start": section.page_start,
                "page_end": section.page_end,
            }
            documents.append(Document(page_content=context_text, metadata=metadata))
            section_contexts[section.section_id] = context_text
        if not documents:
            documents.append(
                Document(
                    page_content="æ–‡æ¡£æš‚æ— å¯ç”¨å†…å®¹ã€‚",
                    metadata={"section_id": "fallback", "title": "Empty"},
                )
            )
        return documents, section_contexts

    def _extract_page_text(self, layout_doc: LayoutDoc) -> dict[int, str]:
        page_text: dict[int, str] = {}
        for page in layout_doc.pages:
            segments: List[str] = []
            for element in page.elements:
                if element.content:
                    segments.append(element.content.strip())
                if element.caption:
                    segments.append(f"{element.kind.value}è¯´æ˜: {element.caption.strip()}")
                if element.latex:
                    segments.append(f"å…¬å¼: {element.latex.strip()}")
            joined = "\n".join(seg for seg in segments if seg).strip()
            if joined:
                page_text[page.page_no] = joined
        return page_text

    def _compose_block_context(self, section: OutlineNode, page_text_map: dict[int, str]) -> str:
        """ç»„ç»‡ä¸Šä¸‹æ–‡ï¼ŒæŒ‰é¡µç é¡ºåºæ¸…æ™°å‘ˆç°ï¼Œæ–¹ä¾¿LLMé€é¡µè®²è§£"""
        page_numbers = self._collect_pages(section)
        page_segments: List[str] = []
        for page in sorted(page_numbers):
            content = page_text_map.get(page)
            if not content:
                continue
            # æ›´æ¸…æ™°çš„é¡µç æ ‡è®°ï¼Œæ–¹ä¾¿LLMè¯†åˆ«
            page_segments.append(f"=== ç¬¬{page}é¡µ ===\n{content}")
        
        summary = (section.summary or "").strip() or "æš‚æ— æ¦‚è¿°ã€‚"
        page_span = self._format_page_span(section)
        
        parts = [
            f"ã€ç« èŠ‚ã€‘{section.title}",
            f"ã€é¡µç èŒƒå›´ã€‘{page_span}",
            f"ã€æ€»ä½“æ¦‚è¿°ã€‘{summary}",
        ]
        
        if page_segments:
            parts.append("\nã€é€é¡µå†…å®¹ã€‘")
            parts.append("\n\n".join(page_segments))
        
        # å¦‚æœæœ‰å­ç« èŠ‚ç»“æ„ï¼Œä¹Ÿæä¾›å‚è€ƒ
        if section.children:
            outline_notes = self._structure_outline_notes(section)
            if outline_notes:
                parts.append("\nã€å­ç« èŠ‚ç»“æ„å‚è€ƒã€‘")
                parts.append(outline_notes)
        
        return "\n".join(parts).strip()

    def _collect_pages(self, section: OutlineNode) -> List[int]:
        pages = list(section.pages or [])
        for anchor in section.anchors:
            pages.append(anchor.page)
        for child in section.children:
            pages.extend(self._collect_pages(child))
        deduped: List[int] = []
        seen = set()
        for page in pages:
            if page in seen:
                continue
            seen.add(page)
            deduped.append(page)
        return sorted(deduped)

    def _format_page_span(self, section: OutlineNode) -> str:
        start = section.page_start or (section.pages[0] if section.pages else None)
        end = section.page_end or (section.pages[-1] if section.pages else None)
        if start and end:
            if start == end:
                return f"p.{start}"
            return f"p.{start}â€“{end}"
        if start:
            return f"p.{start}"
        return "p.?â€“?"

    def generate(
        self,
        session_id: str,
        outline: OutlineTree,
        layout_doc: LayoutDoc,
        detail_level: str,
        difficulty: str,
        language: str,
        progress_callback: Optional[Callable[[Dict[str, object]], None]] = None,
    ) -> NoteDoc:
        """
        Stream a full note document with style-aware prompting.

        The generator now consults StyleProfile directives to split system prompts,
        assemble few-shot structural hints, and post-process the raw LLM output so
        that headersã€summariesã€analogiesã€è¡¨æ ¼ç­‰å¯è§ç»“æ„ä¼šéšç€é£æ ¼è®¾ç½®æ˜æ˜¾å˜åŒ–ã€‚
        """
        try:
            style_profile = build_style_profile(detail_level, difficulty, language)
        except KeyError as exc:
            logger.warning(
                "Unknown style tuple detail=%s tone=%s -> fallback instructions: %s",
                detail_level,
                difficulty,
                exc,
            )
            fallback_text = build_style_instructions(detail_level, difficulty, language)
            style_profile = StyleProfile(
                text=fallback_text,
                directives={"language": language, "summary_mode": "none"},
                example_snippet="",
            )
        enhanced_outline = self._build_natural_outline(layout_doc, outline)
        docs, section_contexts = self._build_semantic_documents(enhanced_outline, layout_doc)
        vector_store = load_or_create(session_id, docs, rebuild=True)
        language_label = "Simplified Chinese" if language == "zh" else "English"
        system_messages = [
            SystemMessage(
                content=(
                    "You are StudyCompanion, tasked with generating structured course notes. "
                    "Adhere strictly to the provided outline and supplied context, and output "
                    "GitHub-flavoured Markdown only. "
                    f"Write every heading, paragraph, bullet, formula, and annotation in {language_label}. "
                    "Respect style directives before answering any follow-up user nudge."
                )
            ),
            SystemMessage(content=f"è¯·éµå®ˆä»¥ä¸‹é£æ ¼è§„åˆ™ï¼š\n{style_profile.text}"),
        ]
        if style_profile.example_snippet:
            system_messages.append(
                SystemMessage(
                    content="ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†æœŸæœ›çš„ Markdown èŠ‚å¥ï¼Œè¯·æ¨¡ä»¿ç»“æ„ï¼š\n"
                    f"{style_profile.example_snippet}"
                )
            )
        sections_to_render = self._flatten_outline(enhanced_outline)
        total_sections = len(sections_to_render)
        
        # ç»Ÿè®¡æ€»é¡µæ•°
        total_pages = sum(len(section.pages or []) for section in sections_to_render)
        
        if progress_callback:
            progress_callback(
                {
                    "phase": "prepare",
                    "message": f"å…± {total_sections} ä¸ªç« èŠ‚ï¼Œè¦†ç›– {total_pages} é¡µPPTï¼Œå‡†å¤‡é€é¡µè®²è§£â€¦",
                }
            )
        
        logger.info(
            "å‡†å¤‡ç”Ÿæˆç¬”è®°: session_id=%s, ç« èŠ‚æ•°=%d, æ€»é¡µæ•°=%d",
            session_id,
            total_sections,
            total_pages
        )
        if progress_callback:
            progress_callback({"phase": "sections_total", "total": total_sections})
        figures_by_page, equations_by_page = self._collect_assets(layout_doc)
        if total_sections == 0:
            save(session_id, vector_store)
            return NoteDoc(
                style={"detail_level": detail_level, "difficulty": difficulty, "language": language},
                toc=[],
                sections=[],
            )

        section_jobs: List[Tuple[int, OutlineNode, str, str]] = []
        for index, section in enumerate(sections_to_render, start=1):
            context_text = section_contexts.get(section.section_id, "")
            prompt = self._build_prompt(section, style_profile, context_text)
            section_jobs.append((index, section, prompt, context_text))

        def render_section(job: Tuple[int, OutlineNode, str, str]) -> Tuple[int, NoteSection]:
            index, section, prompt, context_text = job
            if progress_callback:
                progress_callback(
                    {
                        "phase": "section",
                        "status": "start",
                        "index": index,
                        "total": total_sections,
                        "title": section.title,
                    }
                )
            llm = get_llm(temperature=0.2)
            try:
                response = llm.invoke([*system_messages, HumanMessage(content=prompt)])
                markdown = getattr(response, "content", str(response))
            except Exception as exc:  # pragma: no cover - network guard
                logger.warning("LLM generation failed, using fallback: %s", exc)
                markdown = self._fallback_section(section, context_text)
            markdown = self._post_process_markdown(
                markdown, section, style_profile.directives
            )
            figures = self._resolve_figures(section, figures_by_page)
            equations = self._resolve_equations(section, equations_by_page)
            note_section = NoteSection(
                section_id=section.section_id,
                title=section.title,
                body_md=markdown.strip(),
                figures=figures,
                equations=equations,
                refs=[f"anchor:{section.section_id}@page{a.page}#{a.ref}" for a in section.anchors],
            )
            if progress_callback:
                progress_callback(
                    {
                        "phase": "section",
                        "status": "complete",
                        "index": index,
                        "total": total_sections,
                        "title": section.title,
                    }
                )
            return index, note_section

        sections_map: Dict[int, NoteSection] = {}
        max_workers = min(self.max_workers, total_sections) or 1

        if max_workers == 1:
            for job in section_jobs:
                index, note_section = render_section(job)
                sections_map[index] = note_section
        else:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [executor.submit(render_section, job) for job in section_jobs]
                for future in as_completed(futures):
                    index, note_section = future.result()
                    sections_map[index] = note_section

        sections = [sections_map[index] for index in sorted(sections_map)]
        save(session_id, vector_store)
        toc = [
            {"section_id": section.section_id, "title": section.title}
            for section in enhanced_outline.root.children
        ]
        return NoteDoc(
            style={"detail_level": detail_level, "difficulty": difficulty, "language": language},
            toc=toc,
            sections=sections,
        )

    def _build_prompt(
        self, section: OutlineNode, style_profile: StyleProfile, context_text: str
    ) -> str:
        directives = (style_profile.directives or {}) if style_profile else {}
        page_span = self._format_page_span(section)
        pages = sorted(set(section.pages or []))
        language = directives.get("language", "zh")
        summary_mode = directives.get("summary_mode", "none")
        header_template = directives.get("page_header_template", "### ç¬¬{page}é¡µ")
        page_numbers = pages or [section.page_start or section.page_end or "?"]

        if language == "zh":
            heading_template = "## {title} ({page_span})"
            task_intro = "ã€å†™ä½œä»»åŠ¡ã€‘æŒ‰ç…§ PPT é¡µç é¡ºåºï¼Œé€é¡µè¯¦ç»†è®²è§£æœ¬ç« èŠ‚å†…å®¹ã€‚"
            structure_label = "ã€å¿…é¡»éµå¾ªçš„é€é¡µç»“æ„ã€‘"
            requirements_label = "ã€å†™ä½œè¦æ±‚ã€‘"
            context_label = "ã€å‚è€ƒèµ„æ–™ï¼ˆæŒ‰é¡µç»„ç»‡ï¼‰ã€‘"
            section_label = "ã€ç« èŠ‚æ ‡é¢˜ã€‘"
            summary_label = "ã€æ€»ä½“æ¦‚è¿°ã€‘"
            span_label = "ã€è¦†ç›–é¡µç ã€‘"
            summary_stub = "> **ç« èŠ‚æ´å¯Ÿï¼š** ç”¨ 2-3 å¥è¯ä¸²è”æ¨ç†ã€é™åˆ¶ä¸ä¸‹ä¸€æ­¥æé†’ã€‚"
            concept_line = "- æ ¸å¿ƒæ¦‚å¿µ/é—®é¢˜ï¼šç”¨ 2-3 å¥è¯ç‚¹å‡ºåŠ¨æœºä¸å®šä¹‰ã€‚"
            detail_line = "- æ¨å¯¼ã€æ¡ˆä¾‹æˆ–åº”ç”¨ï¼šäº¤ä»£æ¡ä»¶ã€æ­¥éª¤ä¸ç”¨é€”ã€‚"
            table_stub = "| å¯¹æ¯”é¡¹ | è¯´æ˜ | æç¤º |\n| --- | --- | --- |\n| ç¤ºä¾‹ | åœ¨æ­¤æ¯”è¾ƒå·®å¼‚ | åº”ç”¨çº¿ç´¢ |"
            analogy_stub = "> ğŸ’¡ æ‰“ä¸ªæ¯”æ–¹ï¼šâ€¦â€¦"
            takeaway_stub = "> **ä¸€å¥è¯æ€»ç»“ï¼š** ï¼ˆå¡«å…¥ 1 å¥ takeawayï¼‰"
        else:
            heading_template = "## {title} ({page_span})"
            task_intro = "[Task] Walk through the PPT deck page by page so a student can follow without slides."
            structure_label = "[Structure]"
            requirements_label = "[Writing Requirements]"
            context_label = "[Context grouped by page]"
            section_label = "[Section]"
            summary_label = "[Overview]"
            span_label = "[Page span]"
            summary_stub = "> **Section insight:** Capture the reasoning chain and next-step cues."
            concept_line = "- Core idea / definition: explain why it matters first."
            detail_line = "- Derivation / scenario: outline steps, assumptions, and usage."
            table_stub = "| Aspect | Explanation | Tip |\n| --- | --- | --- |\n| Example | Compare the two ideas | Coach the reader |"
            analogy_stub = "> ğŸ’¡ Analogy: ..."
            takeaway_stub = "> **One-sentence takeaway:** (fill in a one-line takeaway)"

        page_structure_lines: List[str] = []
        for page in page_numbers:
            header = header_template.format(page=page)
            per_page_lines = [header, concept_line, detail_line]
            # ç§»é™¤å¼ºåˆ¶è¡¨æ ¼æ¨¡æ¿ï¼Œè®©LLMæ ¹æ®å†…å®¹è‡ªä¸»é€‰æ‹©
            # if directives.get("use_table"):
            #     per_page_lines.append(table_stub)
            if directives.get("analogy_required"):
                per_page_lines.append(analogy_stub)
            if summary_mode == "takeaway":
                per_page_lines.append(takeaway_stub)
            page_structure_lines.append("\n".join(per_page_lines))

        if summary_mode == "insight":
            page_structure_lines.append(summary_stub)

        page_template = "\n\n".join(page_structure_lines)

        subsection_template = ""
        if section.children:
            label = "ã€å­ç« èŠ‚ç»“æ„ã€‘" if language == "zh" else "[Sub-sections]"
            subsection_template = f"\n\n{label}\n" + self._build_structure_template(section)

        heading_line = heading_template.format(title=section.title, page_span=page_span)
        base_requirements = (
            [
                f"1. ä»¥ `{heading_line}` ä½œä¸ºç« èŠ‚å¤§æ ‡é¢˜ï¼Œå¹¶ä¿æŒ Markdown äºŒçº§æ ‡é¢˜ã€‚",
                "2. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°é¡µç é¡ºåºè¾“å‡ºæ­£æ–‡ï¼Œç¡®ä¿æ¯é¡µè‡³å°‘ 4-6 å¥å®Œæ•´è®²è§£ã€‚",
                "3. **æ™ºèƒ½é€‰æ‹©æ ¼å¼**ï¼šæ ¹æ®å†…å®¹ç‰¹ç‚¹ï¼Œçµæ´»ä½¿ç”¨æ®µè½ã€é¡¹ç›®ç¬¦å·æˆ–è¡¨æ ¼ã€‚",
                "   - **è¡¨æ ¼**ï¼šä»…åœ¨éœ€è¦å¯¹æ¯”å¤šä¸ªé¡¹ç›®ï¼ˆå¦‚ä¼˜ç¼ºç‚¹ã€å¤šç§æ–¹æ³•ã€ç‰¹æ€§å¯¹æ¯”ï¼‰æ—¶ä½¿ç”¨ã€‚",
                "   - **é¡¹ç›®ç¬¦å·ï¼ˆ-ï¼‰**ï¼šç”¨äºç½—åˆ—æ­¥éª¤ã€è¦ç‚¹æ¸…å•ã€å¤šä¸ªç‹¬ç«‹æ¦‚å¿µã€‚",
                "   - **æ®µè½**ï¼šç”¨äºè¿è´¯çš„å™è¿°ã€æ¨å¯¼è¿‡ç¨‹ã€æ¦‚å¿µè§£é‡Šã€‚",
                "4. å›¾ç‰‡å ä½ç¬¦ä½¿ç”¨ `[FIG_PAGE_<é¡µå·>_IDX_<åºå·>: ç”¨é€”è¯´æ˜]` å¹¶è§£é‡Šå…¶å«ä¹‰ã€‚",
                "5. é‡åˆ°å…¬å¼æ—¶ä½¿ç”¨ `$`/`$$` åŒ…è£¹ï¼Œå¹¶é€ä¸ªè§£é‡Šç¬¦å·å«ä¹‰ä¸é€‚ç”¨æ¡ä»¶ã€‚",
            ]
            if language == "zh"
            else [
                f"1. Begin with `{heading_line}` as the section H2 heading.",
                "2. Follow the page order above; each page needs 4-6 flowing sentences.",
                "3. **Choose format intelligently**: Use paragraphs, bullet points, or tables based on content logic.",
                "   - **Tables**: Only when comparing multiple items (pros/cons, methods, features).",
                "   - **Bullet points (-)**: For steps, checklists, or independent key points.",
                "   - **Paragraphs**: For narrative explanations, derivations, or concept introductions.",
                "4. Image placeholders must follow `[FIG_PAGE_<no>_IDX_<idx>: purpose]` and be interpreted in prose.",
                "5. Wrap formulas with `$`/`$$` and describe each symbol plus its constraints.",
            ]
        )

        directive_notes: List[str] = []
        # ç§»é™¤å¼ºåˆ¶è¡¨æ ¼æŒ‡ä»¤ï¼Œæ”¹ä¸ºåœ¨base_requirementsä¸­æä¾›æ™ºèƒ½é€‰æ‹©æŒ‡å—
        # if directives.get("use_table"):
        #     directive_notes.append(
        #         "å½“åŒé¡µå‡ºç°å¤šä¸ªæ¦‚å¿µæ—¶ï¼Œä»¥ Markdown è¡¨æ ¼æ¯”è¾ƒå·®å¼‚ã€ä¼˜ç¼ºç‚¹ã€‚"
        #         if language == "zh"
        #         else "Insert a Markdown table whenever the page contrasts multiple ideas."
        #     )
        formula_mode = directives.get("formula_mode")
        if formula_mode == "light":
            directive_notes.append(
                "å…¬å¼åªä¿ç•™ 1 ä¸ªå…³é”®ç‰ˆæœ¬ï¼Œå¹¶ç”¨å£è¯­è§£é‡Šå®ƒè§£å†³çš„é—®é¢˜ã€‚"
                if language == "zh"
                else "Only keep one key formula and explain the practical problem it solves."
            )
        elif formula_mode == "extended":
            directive_notes.append(
                "éœ€è¦å†™å‡º 2-3 å¥æ¨ç†é“¾ï¼Œè¯´æ˜å˜é‡ã€å‡è®¾ä¸é€‚ç”¨èŒƒå›´ã€‚"
                if language == "zh"
                else "Provide 2-3 sentences of reasoning to unpack variables, assumptions, and scope."
            )
        if directives.get("analogy_required"):
            directive_notes.append(
                "æ¯é¡µè‡³å°‘å†™ä¸€å¥â€œæ‰“ä¸ªæ¯”æ–¹/æ¢å¥è¯è¯´â€ï¼Œå¸®åŠ©å»ºç«‹ç›´è§‰ã€‚"
                if language == "zh"
                else "Each page should include an analogy or 'in other words' sentence."
            )

        if summary_mode == "insight":
            directive_notes.append(
                "ç« èŠ‚æœ«å°¾å†™ 2-3 å¥æ´å¯Ÿ/ä¸‹ä¸€æ­¥æç¤ºã€‚"
                if language == "zh"
                else "Close with 2-3 sentences of section-level insight or next steps."
            )

        if directive_notes:
            extra_header = "é™„åŠ é£æ ¼æç¤ºï¼š" if language == "zh" else "Additional nudges:"
            base_requirements.append(extra_header)
            base_requirements.extend(f"- {note}" for note in directive_notes)

        requirements_block = "\n".join(base_requirements)
        section_summary = (section.summary or "").strip() or (
            "æš‚æ— æ¦‚è¿°ã€‚" if language == "zh" else "No summary available."
        )

        closing = (
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°é€é¡µç»“æ„è¾“å‡ºå®Œæ•´è®²è§£ã€‚"
            if language == "zh"
            else "Follow the structure above exactly and cover every listed page."
        )

        return (
            f"{task_intro}\n\n"
            f"{section_label}{section.title}\n"
            f"{summary_label}{section_summary}\n"
            f"{span_label}{page_span}\n\n"
            f"{structure_label}\n"
            f"{heading_line}\n\n"
            f"{page_template}\n"
            f"{subsection_template}\n\n"
            f"{requirements_label}\n"
            f"{requirements_block}\n\n"
            f"{context_label}\n"
            f"{context_text}\n\n"
            f"{closing}"
        )

    def _build_natural_outline(self, layout_doc: LayoutDoc, fallback: OutlineTree) -> OutlineTree:
        if fallback.root.children:
            return self._ensure_outline_markdown(fallback)
        try:
            page_units = self._extract_page_units(layout_doc)
            if not page_units:
                return self._ensure_outline_markdown(fallback)
            root_children: List[OutlineNode] = []
            level_stack: List[OutlineNode] = []
            for unit in page_units:
                if not unit["title"].strip() and level_stack:
                    self._extend_outline_node(level_stack[-1], unit)
                    continue
                level = max(1, unit["level"])
                while level_stack and level_stack[-1].level >= level:
                    level_stack.pop()
                parent = level_stack[-1] if level_stack else None
                siblings = parent.children if parent else root_children
                existing = (
                    siblings[-1]
                    if siblings
                    and siblings[-1].level == level
                    and self._titles_similar(siblings[-1].title, unit["title"])
                    else None
                )
                if existing:
                    self._extend_outline_node(existing, unit)
                    level_stack.append(existing)
                    continue
                node = OutlineNode(
                    section_id=new_id("ns"),
                    title=unit["title"],
                    summary=unit["summary"],
                    anchors=list(unit["anchors"]),
                    level=level,
                    children=[],
                    pages=list(unit["pages"]),
                    page_start=unit["page_start"],
                    page_end=unit["page_end"],
                )
                siblings.append(node)
                if parent:
                    self._append_unique_anchors(parent, node.anchors)
                level_stack.append(node)
            if not root_children:
                return self._ensure_outline_markdown(fallback)
            root = OutlineNode(
                section_id=fallback.root.section_id,
                title=fallback.root.title,
                summary="è‡ªç„¶ç»“æ„ç« èŠ‚é‡å»ºå®Œæˆã€‚",
                anchors=list(fallback.root.anchors),
                level=0,
                children=root_children,
            )
            return self._outline_with_markdown(root)
        except Exception as exc:  # pragma: no cover - defensive
            logger.warning("è‡ªç„¶ç»“æ„é‡å»ºå¤±è´¥ï¼Œå›é€€æ—§å¤§çº²: %s", exc)
            return self._ensure_outline_markdown(fallback)

    def _extract_page_units(self, layout_doc: LayoutDoc) -> List[dict]:
        units: List[dict] = []
        for page in layout_doc.pages:
            title = ""
            anchors: List[AnchorRef] = []
            body_segments: List[str] = []
            for element in page.elements:
                text = normalize_whitespace(element.content or "")
                if element.kind.value == "title" and not title and text:
                    title = text[:80]
                elif text:
                    body_segments.append(text)
                if element.caption:
                    body_segments.append(normalize_whitespace(element.caption))
                if element.latex:
                    body_segments.append(element.latex)
                if element.ref:
                    anchors.append(AnchorRef(page=page.page_no, ref=element.ref))
            merged_body = " ".join(seg for seg in body_segments if seg)
            summary = take_sentences(merged_body, 3)[:320] if merged_body else ""
            if not summary:
                summary = "æœ¬éƒ¨åˆ†æš‚æ— æ˜ç¡®æ–‡å­—å†…å®¹ï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡ç”Ÿæˆã€‚"
            normalized_title = title or (body_segments[0][:60] if body_segments else "")
            level = self._infer_level(normalized_title)
            units.append(
                {
                    "title": normalized_title or f"é¡µé¢{page.page_no}",
                    "summary": summary,
                    "anchors": anchors[:6] or [AnchorRef(page=page.page_no, ref=f"page-{page.page_no}")],
                    "level": level,
                    "pages": [page.page_no],
                    "page_start": page.page_no,
                    "page_end": page.page_no,
                }
            )
        return units

    def _infer_level(self, title: str) -> int:
        if not title:
            return 3
        normalized = normalize_whitespace(title)
        lowered = normalized.lower()
        if re.match(r"^(chapter|chap\.)\s*\d+", lowered) or re.match(r"^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ä¸¤]+\s*ç« ", normalized):
            return 1
        if re.match(r"^\d+\.\d+\.\d+", normalized):
            return 3
        if re.match(r"^\d+\.\d+", normalized):
            return 2
        if re.match(r"^\d+(\s|-)", normalized):
            return 1
        if len(normalized.split()) <= 4:
            return 1
        return 2

    def _titles_similar(self, left: str, right: str) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæ ‡é¢˜æ˜¯å¦ç›¸ä¼¼ï¼Œç”¨äºæ™ºèƒ½åˆå¹¶ç›¸å…³é¡µé¢"""
        if not left or not right:
            return False
        left_norm = normalize_whitespace(left).lower()
        right_norm = normalize_whitespace(right).lower()
        
        # å®Œå…¨ç›¸åŒæ‰åˆå¹¶
        if left_norm == right_norm:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„æ•°å­—ç¼–å·å‰ç¼€ï¼ˆå¦‚ "1.1" "2.3.1"ï¼‰
        left_prefix = left_norm.split()[0] if left_norm.split() else ""
        right_prefix = right_norm.split()[0] if right_norm.split() else ""
        if left_prefix and right_prefix and re.match(r'^\d+(\.\d+)*$', left_prefix):
            if left_prefix == right_prefix:
                return True
        
        # æ£€æŸ¥å†’å·å‰çš„å…³é”®è¯æ˜¯å¦ç›¸åŒ
        left_key = left_norm.split(":")[0].strip()
        right_key = right_norm.split(":")[0].strip()
        if left_key and right_key and len(left_key) > 3 and left_key == right_key:
            return True
        
        # æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦åˆå¹¶ä¸ç›¸å…³å†…å®¹
        return SequenceMatcher(None, left_norm, right_norm).ratio() >= 0.95

    def _extend_outline_node(self, node: OutlineNode, unit: dict) -> None:
        node.summary = self._merge_summary(node.summary, unit["summary"])
        combined_pages = list(node.pages or [])
        for page in unit.get("pages", []):
            if page not in combined_pages:
                combined_pages.append(page)
        node.pages = combined_pages
        node.page_start = self._min_page(node.page_start, unit.get("page_start"))
        node.page_end = self._max_page(node.page_end, unit.get("page_end"))
        existing = {(anchor.page, anchor.ref) for anchor in node.anchors}
        for anchor in unit["anchors"]:
            key = (anchor.page, anchor.ref)
            if key not in existing:
                node.anchors.append(anchor)
                existing.add(key)

    def _append_unique_anchors(self, node: OutlineNode, anchors: List[AnchorRef]) -> None:
        existing = {(anchor.page, anchor.ref) for anchor in node.anchors}
        for anchor in anchors:
            key = (anchor.page, anchor.ref)
            if key in existing:
                continue
            node.anchors.append(anchor)
            existing.add(key)
            if len(node.anchors) >= 12:
                break

    def _merge_summary(self, left: str, right: str) -> str:
        merged = " ".join(filter(None, [left, right]))
        if not merged:
            return ""
        return take_sentences(merged, 3)[:320] or merged[:320]

    def _min_page(self, current: Optional[int], candidate: Optional[int]) -> Optional[int]:
        if current is None:
            return candidate
        if candidate is None:
            return current
        return min(current, candidate)

    def _max_page(self, current: Optional[int], candidate: Optional[int]) -> Optional[int]:
        if current is None:
            return candidate
        if candidate is None:
            return current
        return max(current, candidate)

    def _flatten_outline(self, outline: OutlineTree) -> List[OutlineNode]:
        """æ‰å¹³åŒ–å¤§çº²ï¼Œåªå–é¡¶å±‚ç« èŠ‚ï¼ˆæ¯ä¸ªç« èŠ‚å†…éƒ¨ä¼šé€é¡µè®²è§£ï¼‰"""
        sections = []
        for child in outline.root.children:
            if child.title.strip():
                sections.append(child)
                # ç¡®ä¿ pages å­—æ®µåŒ…å«æ‰€æœ‰å­ç« èŠ‚çš„é¡µç 
                if child.children:
                    all_pages = set(child.pages or [])
                    for subchild in child.children:
                        all_pages.update(subchild.pages or [])
                    child.pages = sorted(all_pages)
        return sections

    def _build_structure_template(self, section: OutlineNode) -> str:
        lines: List[str] = []

        def visit(node: OutlineNode) -> None:
            level = max(2, min(node.level, 5)) if node.level else 2
            prefix = "#" * level
            lines.append(f"{prefix} {node.title}")
            for child in node.children:
                visit(child)

        visit(section)
        return "\n".join(lines)

    def _structure_outline_notes(self, section: OutlineNode) -> str:
        notes: List[str] = []

        def visit(node: OutlineNode, depth: int = 0) -> None:
            indent = "  " * depth
            summary = (node.summary or "").strip()
            page_span = self._format_page_span(node)
            if summary:
                notes.append(f"{indent}- {node.title} ({page_span}): {summary}")
            else:
                notes.append(f"{indent}- {node.title} ({page_span}): å¾…è¡¥å……")
            for child in node.children:
                visit(child, depth + 1)

        visit(section)
        return "\n".join(notes)

    def _outline_with_markdown(self, root: OutlineNode) -> OutlineTree:
        return OutlineTree(root=root, markdown=render_outline_markdown(root))

    def _ensure_outline_markdown(self, outline: OutlineTree) -> OutlineTree:
        if outline.markdown:
            return outline
        return OutlineTree(root=outline.root, markdown=render_outline_markdown(outline.root))

    def _fallback_section(self, section: OutlineNode, context_text: str) -> str:
        context = context_text.splitlines()[:5]
        bullet_points = "\n".join(f"- {line}" for line in context if line.strip())
        return f"## {section.title}\n\n{section.summary}\n\n{bullet_points}"

    def _post_process_markdown(
        self, markdown: str, section: OutlineNode, directives: Dict[str, object]
    ) -> str:
        text = (markdown or "").strip()
        if not directives:
            return text
        warnings: List[str] = []
        text = self._ensure_page_headers(text, section, directives, warnings)
        text = self._decorate_page_headers(text, section, directives)
        text = self._ensure_summary_blocks(text, directives, warnings)
        if directives.get("analogy_required"):
            text = self._ensure_analogy(text, directives, warnings)
        if directives.get("blockquote_required"):
            text = self._ensure_blockquote(text, directives, warnings)
        if warnings:
            logger.debug(
                "Post-processed section %s with style validators: %s",
                section.section_id,
                "; ".join(warnings),
            )
        return text

    def _ensure_page_headers(
        self,
        text: str,
        section: OutlineNode,
        directives: Dict[str, object],
        warnings: List[str],
    ) -> str:
        template = directives.get("page_header_template", "### ç¬¬{page}é¡µ")
        language = directives.get("language", "zh")
        pages = sorted(set(section.pages or []))
        if not pages:
            return text
        placeholder = (
            "> å¾…è¡¥å……ï¼šè¡¥å†™è¿™ä¸€é¡µçš„ç»†èŠ‚ã€‚"
            if language == "zh"
            else "> TODO: fill in the explanation for this slide."
        )
        updated = text
        for page in pages:
            header = template.format(page=page)
            pattern = rf"^{re.escape(header)}\b"
            if not re.search(pattern, updated, flags=re.MULTILINE):
                updated += f"\n\n{header}\n{placeholder}\n"
                warnings.append(f"missing header {header}")
        return updated

    def _decorate_page_headers(
        self, text: str, section: OutlineNode, directives: Dict[str, object]
    ) -> str:
        language = directives.get("language", "zh")
        if not PAGE_HEADING_PATTERN.search(text):
            return text
        page_titles = self._map_page_outline_titles(section)

        def replace(match: re.Match[str]) -> str:
            page_token = match.group("page_cn") or match.group("page_en")
            if not page_token or not page_token.isdigit():
                return match.group(0)
            page_no = int(page_token)
            level = len(match.group("leading") or "###")
            level = max(2, min(level, 5))
            title = page_titles.get(page_no)
            if not title:
                title = (section.title or "").strip()
            if not title:
                title = f"ç¬¬{page_no}é¡µ" if language == "zh" else f"Page {page_no}"
            badge_label = f"ç¬¬{page_no}é¡µ" if language == "zh" else f"Page {page_no}"
            heading_html = (
                f'<h{level} class="page-heading" data-page="{page_no}">'
                f'<span class="page-heading__title">{escape(title)}</span>'
                f'<span class="page-heading__badge">{escape(badge_label)}</span>'
                f"</h{level}>"
            )
            return heading_html

        return PAGE_HEADING_PATTERN.sub(replace, text)

    def _map_page_outline_titles(self, section: OutlineNode) -> Dict[int, str]:
        page_map: Dict[int, tuple[str, int]] = {}

        def visit(node: OutlineNode, depth: int) -> None:
            title = (node.title or "").strip()
            pages = list(node.pages or [])
            if not pages and node.page_start and node.page_end and node.page_start <= node.page_end:
                pages = list(range(node.page_start, node.page_end + 1))
            if not pages and node.anchors:
                pages = [anchor.page for anchor in node.anchors]
            if not pages:
                pages = self._collect_pages(node)
            pages = list(dict.fromkeys(pages))
            if title and pages:
                for page in pages:
                    current = page_map.get(page)
                    if not current or depth >= current[1]:
                        page_map[page] = (title, depth)
            for child in node.children:
                visit(child, depth + 1)

        visit(section, 1)
        return {page: title for page, (title, _) in page_map.items()}

    def _ensure_summary_blocks(
        self, text: str, directives: Dict[str, object], warnings: List[str]
    ) -> str:
        summary_mode = directives.get("summary_mode")
        if not summary_mode or summary_mode == "none":
            return text
        language = directives.get("language", "zh")
        if summary_mode == "takeaway":
            label = "ä¸€å¥è¯æ€»ç»“" if language == "zh" else "One-sentence takeaway"
            pattern = label.lower()
            haystack = text.lower()
            if pattern not in haystack:
                addition = (
                    f"> **{label}ï¼š** å¾…è¡¥å……ã€‚\n"
                    if language == "zh"
                    else f"> **{label}:** TODO.\n"
                )
                warnings.append("added takeaway summary")
                return text + "\n\n" + addition
            return text
        if summary_mode == "insight":
            label = "ç« èŠ‚æ´å¯Ÿ" if language == "zh" else "Section insight"
            if label.lower() not in text.lower():
                addition = (
                    f"> **{label}ï¼š** è¡¥å†™ 2-3 å¥ä¸²è”æ´å¯Ÿã€‚\n"
                    if language == "zh"
                    else f"> **{label}:** Add 2-3 sentences summarising the reasoning.\n"
                )
                warnings.append("added insight summary")
                return text + "\n\n" + addition
        return text

    def _ensure_analogy(
        self, text: str, directives: Dict[str, object], warnings: List[str]
    ) -> str:
        language = directives.get("language", "zh")
        haystack = text.lower()
        tokens = (
            ["æ‰“ä¸ªæ¯”æ–¹", "æ¢å¥è¯è¯´", "æ¯”å–»", "ç±»æ¯”"]
            if language == "zh"
            else ["analogy", "metaphor", "imagine"]
        )
        if any(token.lower() in haystack for token in tokens):
            return text
        addition = (
            "> ğŸ’¡ æ‰“ä¸ªæ¯”æ–¹ï¼šå¯ä»¥æŠŠæœ¬é¡µå†…å®¹ç±»æ¯”æˆâ€¦â€¦ï¼ˆè¯·è¡¥å†™æ¯”å–»ï¼‰ã€‚"
            if language == "zh"
            else "> ğŸ’¡ Analogy: Describe how this concept mirrors a familiar scenario."
        )
        warnings.append("analogy placeholder injected")
        return text + "\n\n" + addition + "\n"

    def _ensure_blockquote(
        self, text: str, directives: Dict[str, object], warnings: List[str]
    ) -> str:
        if re.search(r"^\s*>", text, flags=re.MULTILINE):
            return text
        language = directives.get("language", "zh")
        addition = (
            "> é‡ç‚¹æé†’ï¼šåœ¨æ­¤å†™ä¸€å¥æ‰¿ä¸Šå¯ä¸‹æˆ–æ³¨æ„äº‹é¡¹ã€‚"
            if language == "zh"
            else "> Key reminder: add a bridging or caution sentence here."
        )
        warnings.append("blockquote placeholder injected")
        return text + "\n\n" + addition + "\n"

    def _collect_assets(
        self, layout_doc: LayoutDoc
    ) -> Tuple[Dict[int, List[LayoutElement]], Dict[int, List[LayoutElement]]]:
        figures: Dict[int, List[LayoutElement]] = defaultdict(list)
        equations: Dict[int, List[LayoutElement]] = defaultdict(list)
        for page in layout_doc.pages:
            for element in page.elements:
                if element.kind.value == "image":
                    figures[page.page_no].append(element)
                if element.kind.value == "formula":
                    equations[page.page_no].append(element)
        return figures, equations

    def _resolve_figures(
        self, section: OutlineNode, figures_by_page: Dict[int, List[LayoutElement]]
    ) -> List[NoteFigure]:
        figures: List[NoteFigure] = []
        for anchor in section.anchors:
            for element in figures_by_page.get(anchor.page, []):
                if element.image_uri:
                    figures.append(
                        NoteFigure(image_uri=element.image_uri, caption=element.caption or "")
                    )
        return figures

    def _resolve_equations(
        self, section: OutlineNode, equations_by_page: Dict[int, List[LayoutElement]]
    ) -> List[NoteEquation]:
        equations: List[NoteEquation] = []
        for anchor in section.anchors:
            for element in equations_by_page.get(anchor.page, []):
                if element.latex:
                    equations.append(
                        NoteEquation(latex=element.latex, caption=element.caption or "")
                    )
        return equations
